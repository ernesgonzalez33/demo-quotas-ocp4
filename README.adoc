= OpenShift 4.x Quotas demo

== Purpose

The following demo has the purpose of showing how quotas work in an OpenShift 4 cluster. This demo is based on the official OpenShift documentation. If you want to learn more, check the documentation here: https://docs.openshift.com/container-platform/4.9/applications/quotas/quotas-setting-per-project.html 

== Prerequisites

* Access to an OpenShift 4.x cluster 
* OpenShift Service Mesh installed

== Demo

Create the project to use for the demo:

`oc new-project quotas-demo`

=== Pods

You can set a quota with the number of pods you want to limit. As the following that only permits one pod

[source, yaml]
----
apiVersion: v1
kind: ResourceQuota
metadata:
  name: quota-pods
spec:
  hard:
    pods: "1" 
----

Apply it to your project:

`oc apply -f quotas/quota-pods.yaml`

See the quota:

[source, bash]
----
$ oc get quota
NAME         AGE   REQUEST     LIMIT
quota-pods   3s    pods: 0/1 
----

Now let's try to deploy an app with two replicas:

`oc apply -f sleep/sleep-two-replicas.yaml`

Let's see how many pods there are:

[source, bash]
----
$ oc get pods
NAME                                  READY   STATUS    RESTARTS   AGE
sleep-two-replicas-6db8bd95ff-c5jj8   1/1     Running   0          26s
----

Only one. Let's check the deployment:

[source, bash]
----
$ oc get deployment
NAME                 READY   UP-TO-DATE   AVAILABLE   AGE
sleep-two-replicas   1/2     1            1           78s
----

The quota is working correctly. To see the error we have to check the events:

[source, bash]
----
$ oc get events
[truncated]
3m38s       Warning   FailedCreate        replicaset/ubi-best-effort-6db8bd95ff      (combined from similar events): Error creating: pods "ubi-best-effort-6db8bd95ff-ggns6" is forbidden: exceeded quota: quota-pods, requested: pods=1, used: pods=1, limited: pods=1
----

Now, let's delete the deployment to continue with the next part of the demo:

`oc delete deployment sleep-two-replicas`

And delete the quota:

`oc delete quota quota-pods`

=== Compute Resources

You can also limit some computing resources, such as CPU and Memory consumption inside a namespace. For example:

[source, yaml]
----
apiVersion: v1
kind: ResourceQuota
metadata:
  name: quota-resources
spec:
  hard:
    requests.cpu: "1" 
    requests.memory: 1Gi 
    limits.cpu: "2" 
    limits.memory: 2Gi 
----

Let's apply the quota:

`oc apply -f quotas/quota-resources.yaml`

An important thing with these kind of quotas is that every application should ask for requests and limits to be able to be deployed. Let's try deploying an app without any request or limits:

[source, bash]
----
$ oc apply -f sleep/sleep-no-resources.yaml 
deployment.apps/sleep-no-resources created
----

The deployment is created. But are there any pods?

[source]
----
$ oc get pods
No resources found in quotas-demo namespace.
----

No pods. To see the error, we need to check the events:

[source]
----
$ oc get events
33s         Warning   FailedCreate        replicaset/sleep-no-resources-6db8bd95ff   (combined from similar events): Error creating: pods "sleep-no-resources-6db8bd95ff-n56s4" is forbidden: failed quota: compute-resources: must specify limits.cpu,limits.memory,requests.cpu,requests.memory
----

We can solve this by putting the requests and limits in the pod. But we are going to do it by using a LimitRange:

`oc apply -f limits/limit-resources.yaml`

Let's recreate the deployment:

`oc delete -f sleep/sleep-no-resources.yaml`

`oc apply -f sleep/sleep-no-resources.yaml`

Now the pod is running:

[source]
----
$ oc get pods
NAME                                 READY   STATUS    RESTARTS   AGE
sleep-no-resources-db844cf47-6kdvs   1/1     Running   0          4s
----

Now let's clean the namespace:

`oc delete deployment sleep-no-resources`

`oc delete quota quota-resources`

`oc delete limitrange limit-resources`

=== Ephemeral Storage

You can also control the ephemeral storage with quotas:

[source, yaml]
----
apiVersion: v1
kind: ResourceQuota
metadata:
  name: storage-resources
spec:
  hard:
    requests.ephemeral-storage: 10Mi
    limits.ephemeral-storage: 20Mi
----

Let's deploy this quota and then and application that only writes to the ephemeral storage.

IMPORTANT: This quota only works if the deployments also have a quota set themselves. Unlike the CPU and Memory quotas, when setting this, the deployments work without setting it explicitly but the quota won't get it.

`oc apply -f quotas/quota-storage.yaml`

`oc apply -f writing/writing.yaml`

Check that the quota is working and the application is running:

[source]
----
$ oc get quota
NAME                AGE   REQUEST                                LIMIT
storage-resources   27s   requests.ephemeral-storage: 1Mi/10Mi   limits.ephemeral-storage: 1Mi/20Mi
$ oc get pods
NAME                                  READY   STATUS    RESTARTS   AGE
writing-deployment-5f6689949c-gzprv   1/1     Running   0          10s
----

The application is writing constantly to the ephemeral storage so check when it is going to be evicted with the following command: `oc get pods -w`

After this, you can clean the exercise:

`oc delete deployment writing-deployment`

`oc delete quota quota-storage`

=== Custom Resources

You can also use quotas to limit the number of Custom Resources. In this case we are going to use the Custom Resources from OpenShift Service Mesh. First of all, let's add our namespace to the Service Mesh:

[source]
----
oc apply -f ossm/smm.yaml
----

Check that is ready:

[source]
----
$ oc get smm
NAME      CONTROL PLANE        READY   AGE
default   istio-system/basic   True    7s
----

Now let's deploy bookinfo in our namespace:

[source]
----
oc apply -f ossm/bookinfo.yaml
----

Wait for all the pods to be ready:

[source]
----
$ oc get pods
NAME                              READY   STATUS    RESTARTS   AGE
details-v1-5bc5947d84-hdm7l       2/2     Running   0          44s
productpage-v1-6fc77ff794-62k2v   2/2     Running   0          43s
reviews-v1-868597db96-gh7s8       2/2     Running   0          44s
----

Now let's create a quota with only one virtual service and three destination rules:

[source, yaml]
----
apiVersion: v1
kind: ResourceQuota
metadata:
  name: quota-ossm
spec:
  hard:
    count/destinationrules.networking.istio.io: 3
    count/virtualservices.networking.istio.io: 1
----

[source]
----
oc apply -f quotas/quota-ossm.yaml
----

Let's check the quota:

[source]
----
oc get quota
NAME         AGE   REQUEST                                                                                           LIMIT
quota-ossm   55m   count/destinationrules.networking.istio.io: 3/3, count/virtualservices.networking.istio.io: 1/1   
----

Now let's try to deploy a new destination rule:app-name:

[source]
----
$ oc apply -f ossm/ratings.yaml 
Error from server (Forbidden): error when creating "ossm/ratings.yaml": destinationrules.networking.istio.io "ratings" is forbidden: exceeded quota: quota-ossm, requested: count/destinationrules.networking.istio.io=1, used: count/destinationrules.networking.istio.io=3, limited: count/destinationrules.networking.istio.io=3
----

=== Cluster Resource Quota

Now let's create a new quota but this time for several projects using the annotation of the requester of the project.

NOTE: For this exercise we are going to use `redhat` as the requester since it is the user we are using. In your cluster replace `redhat` with your user

[source, yaml]
----
apiVersion: quota.openshift.io/v1
kind: ClusterResourceQuota
metadata:
  name: for-user
spec:
  quota:
    hard:
      pods: "10"
  selector:
    annotations:
      openshift.io/requester: redhat
----

`oc apply -f quotas/cluster-resource-quota.yaml`

To see if the quota is correctly applied and where, execute the following command:

[source]
----
$ oc describe AppliedClusterResourceQuota
Name:           for-user
Created:        6 minutes ago
Labels:         <none>
Annotations:    kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"quota.openshift.io/v1","kind":"ClusterResourceQuota","metadata":{"annotations":{},"name":"for-user"},"spec":{"quota":{"hard":{"pods":"10"}},"selector":{"annotations":{"openshift.io/requester":"redhat"}}}}

Namespace Selector: ["istio-system" "quotas-demo"]
Label Selector: 
AnnotationSelector: map[openshift.io/requester:redhat]
Resource        Used    Hard
--------        ----    ----
pods            10      10
----

Right now there are 10 pods used from the 10 pods the user is permitted. So the quota is already filled.

== Clean

To clean the demo:

`oc delete project quotas-demo`